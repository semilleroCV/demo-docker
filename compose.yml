services:
  train:
    build:
      context: .
      dockerfile: Dockerfile
    image: pytorch-uv-app:latest
    container_name: pytorch-train
    command: python train.py
    volumes:
      - ./data:/app/data
      - ./model:/app/model
      - ./runs:/app/runs
      - ./checkpoints:/app/checkpoints
    # environment:
    #   - CUDA_VISIBLE_DEVICES=0
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    restart: "no"

  test:
    build:
      context: .
      dockerfile: Dockerfile
    image: pytorch-uv-app:latest
    container_name: pytorch-test
    command:  python test.py
    volumes:
      - ./data:/app/data
      - ./model:/app/model
      - ./runs:/app/runs
      - ./checkpoints:/app/checkpoints
    # environment:
    #   - CUDA_VISIBLE_DEVICES=0
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    restart: "no"


  tensorboard:
    image: python:3.12-slim
    container_name: pytorch-tensorboard
    command: >
      sh -c "pip install --quiet tensorboard>=2.20.0 && 
             tensorboard --logdir=/app/runs --host=0.0.0.0 --port=6006"
    ports:
      - "6006:6006"
    volumes:
      - ./runs:/app/runs
    restart: unless-stopped
    profiles:
      - monitoring
